{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corridor generation\n",
    "\n",
    "In this notebook, the location of the corridors is being generated based on the voxel seeds. This for the corridors on the groundfloor, that connect al communal functions and all housing entrances. The public functions have their own entrance on street level.\n",
    "For each function seed and the entrance location a shaft location is generated, and a connection is found to two of their closest shafts to generate a corridornetwork for this floor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initialization\n",
    "\n",
    "### 0.1. Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import topogenesis as tg\n",
    "import pyvista as pv\n",
    "import trimesh as tm\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "np.random.seed(0)\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra import function\n",
    "def lattice_from_csv(file_path):\n",
    "    # read metadata\n",
    "    meta_df = pd.read_csv(file_path, nrows=3)\n",
    "\n",
    "    shape = np.array(meta_df['shape'])\n",
    "    unit = np.array(meta_df['unit'])\n",
    "    minbound = np.array(meta_df['minbound'])\n",
    "\n",
    "    # read lattice\n",
    "    lattice_df = pd.read_csv(file_path, skiprows=5)\n",
    "\n",
    "    # create the buffer\n",
    "    buffer = np.array(lattice_df['value']).reshape(shape)\n",
    "\n",
    "    # create the lattice\n",
    "    l = tg.to_lattice(buffer, minbound=minbound, unit=unit)\n",
    "\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Define the Neighborhood (Stencil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating neighborhood definition\n",
    "s_1 = tg.create_stencil(\"von_neumann\", 1, 1)\n",
    "\n",
    "# setting the center to zero\n",
    "s_1.set_index([0,0,0], 0)\n",
    "\n",
    "# creating neighborhood definition\n",
    "s_2 = tg.create_stencil(\"von_neumann\", 1, 2)\n",
    "# setting the center to zero\n",
    "s_2.set_index([0, 0, 0], 0)\n",
    "s_2.set_index([0, 0, 1], 0)\n",
    "s_2.set_index([0, 0, 2], 1)\n",
    "s_2.set_index([0, 0,-1], 0)\n",
    "s_2.set_index([0, 0,-2], 1)\n",
    "\n",
    "# setting the center to zero\n",
    "s_2.set_index([0,0,0], 0)\n",
    "\n",
    "# creating neighborhood definition\n",
    "s_3 = tg.create_stencil(\"von_neumann\", 1, 3)\n",
    "# setting the center to zero\n",
    "s_3.set_index([0, 0, 0], 0)\n",
    "s_3.set_index([0, 0, 1], 0)\n",
    "s_3.set_index([0, 0, 3], 1)\n",
    "s_3.set_index([0, 0,-1], 0)\n",
    "s_3.set_index([0, 0,-3], 1)\n",
    "\n",
    "# setting the center to zero\n",
    "s_3.set_index([0,0,0], 0)\n",
    "\n",
    "# creating neighborhood definition\n",
    "s_groundfloor = tg.create_stencil(\"von_neumann\", 1, 1)\n",
    "\n",
    "# setting the center to zero\n",
    "s_groundfloor.set_index([0, 0, 0], 0)\n",
    "s_groundfloor.set_index([0, 0, 1], 0)\n",
    "s_groundfloor.set_index([0, 0,-1], 0)\n",
    "\n",
    "stencils = [s_1, s_2, s_3, s_groundfloor]\n",
    "\n",
    "h_stencil = s_groundfloor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3. Load the envelope lattice as the avialibility lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the lattice from csv\n",
    "lattice_path = os.path.relpath('../data/highres_envelope.csv')\n",
    "avail_lattice = lattice_from_csv(lattice_path)\n",
    "\n",
    "# loading the lattice from csv\n",
    "lattice_path = os.path.relpath('../data/avail_lattice_good_voxels.csv')\n",
    "avail_lattice_good_voxels = lattice_from_csv(lattice_path)\n",
    "init_avail_lattice = tg.to_lattice(np.copy(avail_lattice_good_voxels), avail_lattice_good_voxels)\n",
    "\n",
    "avail_lattice*= avail_lattice_good_voxels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4. Load Agents Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading program (agents information) from CSV\n",
    "prgm_path = os.path.relpath('../data/program_exported.csv')\n",
    "agn_info = pd.read_csv('../data/program_exported.csv',delimiter=\";\")\n",
    "agn_ids = agn_info[\"space_id\"].values\n",
    "agn_prefs = agn_info\n",
    "a_pref = agn_prefs.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading program information between agents from CSV\n",
    "matrix_path = os.path.relpath('../data/program_exported_matrix.csv')\n",
    "matrix_info = pd.read_csv('../data/program_exported_matrix.csv',delimiter=\";\")\n",
    "matrix_ids = matrix_info[\"space_id\"].values\n",
    "matrix_prefs = matrix_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5. Initialize environment information layers from Sun Access Lattice and Entrance Access Lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the lattice from csv\n",
    "sun_acc_path = os.path.relpath('../data/sun_access_highres.csv')\n",
    "sun_acc_lattice = lattice_from_csv(sun_acc_path)\n",
    "\n",
    "ent_acc_highres_public_path = os.path.relpath('../data/ent_access_highres_public.csv')\n",
    "ent_acc_public_lattice = lattice_from_csv(ent_acc_highres_public_path)\n",
    "\n",
    "ent_acc_highres_housing_path = os.path.relpath('../data/ent_access_highres_housing.csv')\n",
    "ent_acc_housing_lattice = lattice_from_csv(ent_acc_highres_housing_path)\n",
    "\n",
    "ent_acc_highres_gym_path = os.path.relpath('../data/ent_access_highres_gym.csv')\n",
    "ent_acc_gym_lattice = lattice_from_csv(ent_acc_highres_gym_path)\n",
    "\n",
    "ent_acc_highres_parking_path = os.path.relpath('../data/ent_access_highres_parking.csv')\n",
    "ent_acc_parking_lattice = lattice_from_csv(ent_acc_highres_parking_path)\n",
    "\n",
    "ent_acc_highres_comcen_path = os.path.relpath('../data/ent_access_highres_comcen.csv')\n",
    "ent_acc_comcen_lattice = lattice_from_csv(ent_acc_highres_comcen_path)\n",
    "\n",
    "highres_sky_acc_path = os.path.relpath('../data/sky_access_highres.csv')\n",
    "sky_acc_lattice = lattice_from_csv(highres_sky_acc_path)\n",
    "\n",
    "highres_quietness_acc_path = os.path.relpath('../data/quietness_highres.csv')\n",
    "quietness_acc_lattice = lattice_from_csv(highres_quietness_acc_path)\n",
    "\n",
    "groundfloor_acc_path = os.path.relpath('../data/ent_access_highres_groundfloor.csv')\n",
    "groundfloor_acc_lattice = lattice_from_csv(groundfloor_acc_path)\n",
    "\n",
    "# list the environment information layers (lattices)\n",
    "env_info = {\"sun_acc\": sun_acc_lattice + 0.001,\n",
    "            \"ent_acc_public\": ent_acc_public_lattice + 0.001, \n",
    "            \"ent_acc_housing\": ent_acc_housing_lattice + 0.001, \n",
    "            \"ent_acc_gym\": ent_acc_gym_lattice + 0.001,\n",
    "            \"ent_acc_parking\": ent_acc_parking_lattice + 0.001, \n",
    "            \"ent_acc_comcen\": ent_acc_comcen_lattice + 0.001,\n",
    "            \"sky_acc\": sky_acc_lattice + 0.001,\n",
    "            \"quietness_acc\": quietness_acc_lattice + 0.001,\n",
    "            \"ground_floor_acc\": groundfloor_acc_lattice + 0.001}\n",
    "\n",
    "# defining other factors in csv\n",
    "# defining stencil id\n",
    "stencil_id = stencils\n",
    "# area to use in simulation\n",
    "room_area = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a list of all communal functions\n",
    "community = []\n",
    "print(agn_info[\"ent_acc_comcen\"].values)\n",
    "\n",
    "\n",
    "for i in agn_ids:\n",
    "    if agn_info[\"ent_acc_comcen\"][i] == 1:\n",
    "        \n",
    "        community.append(agn_ids[i])\n",
    "print(community)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. initial agent localisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_avail(avail_lattice, ind, a_stencil_id):\n",
    "    condition = 1\n",
    "    ind_array = np.array(ind)\n",
    "    for step in range(a_stencil_id + 1):\n",
    "        new_ind_array = ind_array + np.array([0,0,step])\n",
    "        condition *= avail_lattice[tuple(new_ind_array)]\n",
    "    return condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_voxel(vox, env_info, a_pref):\n",
    "    global_vox_value = 1.0\n",
    "    # for every lattice in the environment informations\n",
    "    for key, info_lattice in env_info.items():\n",
    "        # Here we utilise Fuzzy Logics to be able to compare different layers \n",
    "        # of environmental information and evaluate the voxel for the agent. \n",
    "        # This method is introduced, and generalised in Pirouz Nourian dissertation: \n",
    "        # section 5.7.3, pp. 201-208, eq. 57. You can refer to this section for \n",
    "        # comprehensive mathematical details.\n",
    "        vox_val = info_lattice[tuple(vox)]\n",
    "        agn_vox_val = np.power(vox_val, a_pref[key])\n",
    "        global_vox_value *= agn_vox_val\n",
    "    \n",
    "    return global_vox_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_occupation(selected_vox_3d_address, a_id, a_height, agn_locs, agn_src_locs, occ_lattice, avail_lattice, departure=False):\n",
    "    for step in range(a_height):\n",
    "\n",
    "        new_address = selected_vox_3d_address + np.array([0,0,step])\n",
    "        if new_address[2] < occ_lattice.shape[2]:\n",
    "            # make tuple of the address\n",
    "            selected_vox_3d_id = tuple(new_address)\n",
    "            # find the location of the newly selected voxel\n",
    "            selected_vox_loc = np.array(selected_vox_3d_id).flatten()\n",
    "\n",
    "            if departure==False:\n",
    "                # add the newly selected voxel location to agent locations\n",
    "                agn_locs[a_id].append(selected_vox_loc)\n",
    "                if step ==0:\n",
    "                    agn_src_locs[a_id].append(selected_vox_loc)\n",
    "                # set the newly selected voxel as UNavailable (0) in the availability lattice\n",
    "                avail_lattice[selected_vox_3d_id] = 0\n",
    "                # set the newly selected voxel as OCCUPIED by current agent \n",
    "                # (-1 means not-occupied so a_id)\n",
    "                occ_lattice[selected_vox_3d_id] = a_id\n",
    "            else:\n",
    "                # remove the newly selected voxel location to agent locations\n",
    "                a_locs_list = [list(loc) for loc in agn_locs[a_id]]\n",
    "                try:\n",
    "                    ind = a_locs_list.index(list(selected_vox_loc))\n",
    "                    agn_locs[a_id].pop(ind)\n",
    "\n",
    "                    # set the newly selected voxel as UNavailable (0) in the availability lattice\n",
    "                    avail_lattice[selected_vox_3d_id] = 1\n",
    "                    # set the newly selected voxel as OCCUPIED by current agent \n",
    "                    # (-1 means not-occupied so a_id)\n",
    "                    occ_lattice[selected_vox_3d_id] =  -1\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    return (agn_locs, agn_src_locs, occ_lattice, avail_lattice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_voxels_masked(lattice, stencil, loc):\n",
    "    vox_locs = np.argwhere(stencil) - stencil.origin + loc\n",
    "    vox_filter = np.all(vox_locs > 0, axis=1) * np.all(vox_locs < np.array(lattice.shape), axis=1)\n",
    "    return(vox_locs[vox_filter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the occupation lattice\n",
    "occ_lattice = avail_lattice * 0 - 1\n",
    "\n",
    "# Finding the index of the available voxels in avail_lattice\n",
    "avail_flat = avail_lattice.flatten()\n",
    "avail_index = np.array(np.where(avail_lattice == 1)).T\n",
    "\n",
    "# count the number of spaces and intiialize an agent for each space\n",
    "agn_num = len(agn_info)\n",
    "\n",
    "# adding the origins to the agents locations\n",
    "agn_locs = [[] for a_id in agn_ids]\n",
    "agn_src_locs = [[] for a_id in agn_ids]\n",
    "agn_upper = []\n",
    "\n",
    "# retrieving the initial location of each agent\n",
    "for a_id in community:    \n",
    "    voxel_vals = []\n",
    "    pot_voxels = []\n",
    "    # retrieve agent preferences\n",
    "    a_pref = agn_prefs.loc[a_id]\n",
    "    a_stencil_id = 0\n",
    "    stencil = stencils[a_stencil_id]\n",
    "    # use avail_index voxel Evaluation Loop\n",
    "    for pot_vox in avail_index:         \n",
    "        if check_avail(avail_lattice, tuple(pot_vox), a_stencil_id):\n",
    "            # evaluate each voxel\n",
    "            vox_value = eval_voxel(pot_vox, env_info, a_pref)\n",
    "            # add the voxel value to the list of values\n",
    "            voxel_vals.append(vox_value)\n",
    "            pot_voxels.append(pot_vox)\n",
    "\n",
    "    # convert voxel values to numpy array\n",
    "    voxel_vals = np.array(voxel_vals)\n",
    "    # convert potential voxels to numpy array\n",
    "    pot_voxels = np.array(pot_voxels)\n",
    "    # select the voxel with highest value \n",
    "    selected_int = np.argmax(voxel_vals) \n",
    "    # find 3D intiger index of selected voxel\n",
    "    selected_vox_3d_address = tuple(pot_voxels[selected_int].T)\n",
    "    # find the location of the newly selected voxel\n",
    "    agn_origins = np.array(selected_vox_3d_address).flatten()\n",
    "    # Occupy the newly selected voxel in the occupation lattice\n",
    "    occ_lattice[selected_vox_3d_address] = 5\n",
    "    \n",
    "    agn_locs, agn_src_locs, occ_lattice, avail_lattice = mult_occupation(selected_vox_3d_address, \n",
    "                                                                       a_id, \n",
    "                                                                       a_stencil_id + 1, \n",
    "                                                                       agn_locs,\n",
    "                                                                       agn_src_locs,\n",
    "                                                                       occ_lattice, \n",
    "                                                                       avail_lattice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add entrance voxel to the occ_lattice\n",
    "occ_lattice[(83, 20, 1)] = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Visualizing the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p = pv.Plotter(notebook=True)\n",
    "\n",
    "base_lattice = occ_lattice\n",
    "\n",
    "# Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data\n",
    "grid = pv.UniformGrid()\n",
    "grid.dimensions = np.array(base_lattice.shape) + 1\n",
    "# The bottom left corner of the data set\n",
    "grid.origin = base_lattice.minbound - base_lattice.unit * 0.5\n",
    "# These are the cell sizes along each axis\n",
    "grid.spacing = base_lattice.unit \n",
    "\n",
    "# adding the boundingbox wireframe\n",
    "p.add_mesh(grid.outline(), color=\"grey\", label=\"Domain\")\n",
    "\n",
    "# adding the avilability lattice\n",
    "\n",
    "# adding axes\n",
    "p.add_axes()\n",
    "p.show_bounds(grid=\"back\", location=\"back\", color=\"#aaaaaa\")\n",
    "\n",
    "agn_num = len(agn_info)\n",
    "\n",
    "def create_mesh(value):\n",
    "    f = int(value)\n",
    "    lattice = base_lattice\n",
    "\n",
    "    # Add the data values to the cell data\n",
    "    grid.cell_arrays[\"Agents\"] = lattice.flatten(order=\"F\").astype(int)  # Flatten the array!\n",
    "    # filtering the voxels\n",
    "    threshed = grid.threshold([-0.1, 20])\n",
    "    # adding the voxels\n",
    "    p.add_mesh(threshed, name='sphere', show_edges=True, opacity=1.0, show_scalar_bar=False)\n",
    "\n",
    "    return\n",
    "\n",
    "p.add_slider_widget(create_mesh, [0, 1], title='Time', value=0, event_type=\"always\", style=\"classic\", pointa=(0.1, 0.1), pointb=(0.9, 0.1))\n",
    "p.show(use_ipyvtk=True)\n",
    "\n",
    "#saving and plotting\n",
    "png_path = os.path.relpath('../screenshots/5.1_voxel_seeds_groundfloor.png')\n",
    "p.show(screenshot= png_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the ground floor latice to csv \n",
    "csv_path = os.path.relpath('../data/voxel_seeds.csv')\n",
    "occ_lattice.to_csv(csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. for each seed, generate a shaft location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_01_lattice = (occ_lattice > -1).astype(int)\n",
    "# compute the sum over the columns to add weight to locations that might have multiple seeds above eachother\n",
    "column_sum = np.sum(occupation_01_lattice, axis = 2)\n",
    "\n",
    "max_value_seeds = np.max(column_sum)\n",
    "filled_col_list = []\n",
    "\n",
    "for i in range(1, max_value_seeds + 1): \n",
    "    # find adresses of columns\n",
    "    column_adress = np.where(column_sum == i )\n",
    "    filled_collumns = np.array(column_adress).T\n",
    "    filled_col_list.append(filled_collumns)\n",
    "\n",
    "fill_col_stacked = np.vstack(filled_col_list) \n",
    "clusters = len(fill_col_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=clusters, random_state=0).fit(fill_col_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_labels = kmeans.labels_\n",
    "cluster_centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an empty occ lattice\n",
    "cluster_lattice = occ_lattice * 0 - 1\n",
    "# iterating over each filled column\n",
    "for col, lab in zip(fill_col_stacked, col_labels):\n",
    "    # setting the base of the column into the label value\n",
    "    cluster_lattice[col[0], col[1], :] = lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Compute a distance graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_cluster_centres = np.rint(cluster_centers).astype(int)\n",
    "\n",
    "shaft_lattice = occ_lattice * 0 \n",
    "# iterating over each shaft\n",
    "for i, cen in enumerate(rounded_cluster_centres): \n",
    "        shaft_lattice[cen[0], cen[1], :] = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_shft_latice = shaft_lattice * init_avail_lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the number of all voxels\n",
    "vox_count = avail_lattice.size \n",
    "\n",
    "# initialize the adjacency matrix\n",
    "adj_list = []\n",
    "\n",
    "# Finding the index of the available voxels in avail_lattice\n",
    "avail_index = np.array(np.where(avail_lattice == 1)).T\n",
    "\n",
    "# fill the adjacency matrix using the list of all neighbours\n",
    "for vox_loc in avail_index:\n",
    "    # find the 1D id\n",
    "    vox_id = np.ravel_multi_index(vox_loc, avail_lattice.shape)\n",
    "    # check whether it is in a shaft or not\n",
    "    if shaft_lattice[tuple(vox_loc)] > 0:\n",
    "        # in case that specific voxel is in a shaft\n",
    "        vox_stencil = stencil\n",
    "    else: \n",
    "        # in case that the voxel is a normal voxel\n",
    "        vox_stencil = h_stencil\n",
    "        \n",
    "    # retrieve the list of neighbours of the voxel based on the stencil\n",
    "    vox_neighs = avail_lattice.find_neighbours_masked(vox_stencil, loc = vox_loc)\n",
    "    # iterating over the neighbours\n",
    "    for neigh in vox_neighs:\n",
    "        # setting the entry to one\n",
    "        # adj_mtrx[vox_id, neigh] = 1.0\n",
    "        adj_list.append([1.0, vox_id, neigh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_array = np.array(adj_list)\n",
    "adj_mtrx_sparse = sp.sparse.csr_matrix((adj_array[:,0],(adj_array[:,1],adj_array[:,2])), shape=(vox_count, vox_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.from_scipy_sparse_matrix(adj_mtrx_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. construct the corridors based on the shortest paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corridor_lattice = occ_lattice * 0 -1\n",
    "        \n",
    "corr_flat = corridor_lattice.flatten()\n",
    "cor_groundfloor = shaft_lattice[:, :, 1]\n",
    "\n",
    "shaft_vox_inds = np.array(np.where(cor_groundfloor >0)).T\n",
    "corr_latt_shape = corridor_lattice.shape        \n",
    "\n",
    "all_shortest_paths = []\n",
    "# find the shortest path between all locations to generate a corridor network\n",
    "for start_shaft in  shaft_vox_inds:\n",
    "    paths = []\n",
    "    path_lenghts = []\n",
    "    for dist_shaft_ind in shaft_vox_inds: \n",
    "        # construct the destination adress\n",
    "        src_vox = np.array([start_shaft[0], start_shaft[1], 2])\n",
    "        dst_vox = np.array([dist_shaft_ind[0], dist_shaft_ind[1], 2])\n",
    "        # construct 1-dimentional indices\n",
    "        src_ind = np.ravel_multi_index(src_vox, corr_latt_shape)\n",
    "        dst_ind = np.ravel_multi_index(dst_vox, corr_latt_shape)\n",
    "        # find the shortest path\n",
    "        try: \n",
    "            path = nx.algorithms.shortest_paths.astar.astar_path(g, src_ind, dst_ind)\n",
    "\n",
    "            if len(path) > 1: \n",
    "                paths.append(path)\n",
    "                path_lenghts.append(len(path))\n",
    "        except: \n",
    "            pass\n",
    "        \n",
    "    path_order = np.argsort(np.array(path_lenghts))\n",
    "    shortest_path = paths[path_order[1]]\n",
    "    all_shortest_paths.append(paths)\n",
    "          \n",
    "corridor_lattice = corr_flat.reshape(corridor_lattice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the corridors to all voxels that should make use of these corridors (3 voxels heigh for first level, two voxels heigh for second level)\n",
    "for i, path in enumerate(all_shortest_paths):\n",
    "    for cen in path: \n",
    "        thrd_ind = np.unravel_index(cen, corridor_lattice.shape)\n",
    "        corridor_lattice[thrd_ind[0], thrd_ind[1], :6] = 1\n",
    "        corridor_lattice[thrd_ind[0], thrd_ind[1], 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p = pv.Plotter(notebook=True)\n",
    "\n",
    "base_lattice = corridor_lattice\n",
    "\n",
    "# Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data\n",
    "grid = pv.UniformGrid()\n",
    "grid.dimensions = np.array(base_lattice.shape) + 1\n",
    "# The bottom left corner of the data set\n",
    "grid.origin = base_lattice.minbound - base_lattice.unit * 0.5\n",
    "# These are the cell sizes along each axis\n",
    "grid.spacing = base_lattice.unit \n",
    "\n",
    "# adding the boundingbox wireframe\n",
    "\n",
    "p.add_mesh(grid.outline(), color=\"grey\", label=\"Domain\")\n",
    "\n",
    "# adding the avilability lattice\n",
    "# init_avail_lattice.fast_vis(p)\n",
    "\n",
    "# adding axes\n",
    "p.add_axes()\n",
    "p.show_bounds(grid=\"back\", location=\"back\", color=\"#aaaaaa\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add the data values to the cell data\n",
    "grid.cell_arrays[\"Agents\"] = base_lattice.flatten(order=\"F\").astype(int)  # Flatten the array!\n",
    "# filtering the voxels\n",
    "threshed = grid.threshold([-0.1, 20])\n",
    "# adding the voxels\n",
    "p.add_mesh(threshed, name='sphere', show_edges=True, opacity=1.0, show_scalar_bar=False)\n",
    "\n",
    "\n",
    "# p.add_slider_widget(create_mesh, [0, n_frames], title='Time', value=0, event_type=\"always\", style=\"classic\", pointa=(0.1, 0.1), pointb=(0.9, 0.1))\n",
    "p.show(use_ipyvtk=True)\n",
    "\n",
    "#saving and plotting\n",
    "png_path = os.path.relpath('../screenshots/5.2_corridors_groundfloor.png')\n",
    "p.show(screenshot= png_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Saving lattice frames in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the ground floor latice to csv \n",
    "csv_path = os.path.relpath('../data/corridors_groundfloor.csv')\n",
    "corridor_lattice.to_csv(csv_path)\n",
    "\n",
    "import pickle\n",
    "lattice_pickle_path = os.path.relpath('../data/corridors_groundfloor.p')\n",
    "pickle.dump(corridor_lattice, open(lattice_pickle_path,\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Shervin Azadi and Pirouz Nourian\"\n",
    "__editor__ = \"Maartje Damen\"\n",
    "__license__ = \"MIT\"\n",
    "__version__ = \"1.0\"\n",
    "__url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\"\n",
    "__summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}