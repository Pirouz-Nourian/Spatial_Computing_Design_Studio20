{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shafts and shortest path finding\n",
    "[More about shafts and shortest paths finding](/spatial_computing_project_template/index/scripts/corridors/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will first place the agents in an optimal place by loading in previously computed csv's.\n",
    "Next, we will manually place shafts to make sure that there will be a shaft on the highest floor levels.\n",
    "Finally, we will compute shortest paths between:\n",
    "1. an agent and a shaft\n",
    "2. a shaft and another shaft on the ground floor\n",
    "3. a shaft and another shaft on a higher floor level\n",
    "\n",
    "The inputs of this notebook are the final voxelized envelope, the full voxelized envelope and the immediate context. We need the full voxelized envelope without the valley for computing shafts on a higher floor level. The immediate context is only used for visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initialization\n",
    "\n",
    "### 0.1. Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import topogenesis as tg\n",
    "import pyvista as pv\n",
    "import trimesh as tm\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.cluster import KMeans\n",
    "np.random.seed(0)\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "import copy\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra import function\n",
    "def lattice_from_csv(file_path):\n",
    "    # read metadata\n",
    "    meta_df = pd.read_csv(file_path, nrows=3)\n",
    "\n",
    "    shape = np.array(meta_df['shape'])\n",
    "    unit = np.array(meta_df['unit'])\n",
    "    minbound = np.array(meta_df['minbound'])\n",
    "\n",
    "    # read lattice\n",
    "    lattice_df = pd.read_csv(file_path, skiprows=5)\n",
    "\n",
    "    # create the buffer\n",
    "    buffer = np.array(lattice_df['value']).reshape(shape)\n",
    "\n",
    "    # create the lattice\n",
    "    l = tg.to_lattice(buffer, minbound=minbound, unit=unit)\n",
    "\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Define the Neighborhood (Stencil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating neighborhood definition\n",
    "stencil = tg.create_stencil(\"von_neumann\", 1, 1)\n",
    "# setting the center to zero\n",
    "stencil.set_index([0,0,0], 0)\n",
    "\n",
    "# creating neighborhood definition\n",
    "stencil2 = tg.create_stencil(\"von_neumann\", 1, 1)\n",
    "# setting the center to zero\n",
    "stencil2.set_index([0, 0, 0], 0)\n",
    "stencil2.set_index([0, 0, 1], 0)\n",
    "stencil2.set_index([0, 0, -1], 0)\n",
    "\n",
    "# creating neighborhood definition - center with 0 neighbours\n",
    "s_z = tg.create_stencil(\"von_neumann\", 0, 1)\n",
    "# setting the center to zero\n",
    "s_z.set_index([0, 0, 0], 0)\n",
    "# setting z neighbours to 1\n",
    "s_z.set_index([0, 0,-1], 1)\n",
    "s_z.set_index([0, 0, 1], 1)\n",
    "\n",
    "# creating neighborhood definition - center with 1x neighbours\n",
    "s_xy = tg.create_stencil(\"von_neumann\", 1, 1)\n",
    "# setting the center to zero\n",
    "s_xy.set_index([0, 0, 0], 0)\n",
    "# setting z neighbours to 0\n",
    "s_xy.set_index([0, 0, 1], 0)\n",
    "s_xy.set_index([0, 0, -1], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3. Load the envelope lattice as the avialbility lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the envelope lattice from csv\n",
    "lattice_path = os.path.relpath('../data/final_envelope_new.csv')\n",
    "avail_lattice = lattice_from_csv(lattice_path) \n",
    "init_avail_lattice = tg.to_lattice(np.copy(avail_lattice), avail_lattice) \n",
    "\n",
    "# loading the lattice full lattice from csv\n",
    "lattice_path = os.path.relpath('../data/envelope_highres_new.csv')\n",
    "full_lattice = lattice_from_csv(lattice_path) \n",
    "init_full_lattice = tg.to_lattice(np.copy(full_lattice), full_lattice) \n",
    "\n",
    "#loading the immediate context as obj\n",
    "immediate_context = os.path.relpath('../data/immediate_context.obj')\n",
    "immediate_context_mesh = tm.load(immediate_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4. Load Agents Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading program (agents information) from CSV\n",
    "prgm_path = os.path.relpath('../data/program.csv')\n",
    "agn_info = np.genfromtxt(prgm_path, delimiter=',')[1:, 1:]\n",
    "# extract agent ids\n",
    "agn_ids = agn_info[:, 0]\n",
    "# extract agent preferences\n",
    "agn_prefs = agn_info[:, 1:]\n",
    "# extract agent preference to expand in the z-direction\n",
    "agn_expandz = agn_info[:, 38]\n",
    "# extract maximum voxels of each agent agent. This represents the maximu8m area & volume\n",
    "agn_vox_req = agn_info[:, 39]\n",
    "agn_silent_level = agn_info[:, 43]\n",
    "agn_noise_repel = agn_info[:, 44]\n",
    "agn_info_df = pd.read_csv('../data/program.csv') \n",
    "#print (agn_info_df[\"student_housing_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the lattice from csv\n",
    "sun_acc_path = os.path.relpath('../data/sun_access_highres.csv')\n",
    "sun_acc_lattice = lattice_from_csv(sun_acc_path)\n",
    "\n",
    "# loading the lattice from csv\n",
    "ent1_acc_path = os.path.relpath('../data/ent1_access.csv')\n",
    "ent1_acc_lattice = lattice_from_csv(ent1_acc_path)\n",
    "\n",
    "# loading the lattice from csv\n",
    "ent2_acc_path = os.path.relpath('../data/ent2_access.csv')\n",
    "ent2_acc_lattice = lattice_from_csv(ent2_acc_path)\n",
    "\n",
    "# loading the lattice from csv\n",
    "ent3_1_acc_path = os.path.relpath('../data/ent3.1_access.csv')\n",
    "ent3_1_acc_lattice = lattice_from_csv(ent3_1_acc_path)\n",
    "\n",
    "# loading the lattice from csv\n",
    "ent3_2_acc_path = os.path.relpath('../data/ent3.2_access.csv')\n",
    "ent3_2_acc_lattice = lattice_from_csv(ent3_2_acc_path)\n",
    "\n",
    "# loading the lattice from csv\n",
    "ent3_3_acc_path = os.path.relpath('../data/ent3.3_access.csv')\n",
    "ent3_3_acc_lattice = lattice_from_csv(ent3_3_acc_path)\n",
    "\n",
    "# loading the lattice from csv\n",
    "ent4_acc_path = os.path.relpath('../data/ent4_access.csv')\n",
    "ent4_acc_lattice = lattice_from_csv(ent4_acc_path)\n",
    "\n",
    "# loading the lattice from csv\n",
    "ent5_acc_path = os.path.relpath('../data/ent5_access.csv')\n",
    "ent5_acc_lattice = lattice_from_csv(ent5_acc_path)\n",
    "\n",
    "# loading the lattice from csv\n",
    "ent6_acc_path = os.path.relpath('../data/ent6_access.csv')\n",
    "ent6_acc_lattice = lattice_from_csv(ent6_acc_path)\n",
    "\n",
    "# loading the lattice from csv\n",
    "ent7_acc_path = os.path.relpath('../data/ent7_access.csv')\n",
    "ent7_acc_lattice = lattice_from_csv(ent7_acc_path)\n",
    "\n",
    "# loading the lattice from csv\n",
    "noise_acc_path = os.path.relpath('../data/HeerBokelweg_noise.csv')\n",
    "noise_acc_lattice = lattice_from_csv(noise_acc_path)\n",
    "\n",
    "# loading the lattice from csv\n",
    "public_green_acc_path = os.path.relpath('../data/public_greenery_highres.csv')\n",
    "public_green_acc_lattice = lattice_from_csv(public_green_acc_path)\n",
    "\n",
    "# loading the lattice from csv\n",
    "intern_green_acc_path = os.path.relpath('../data/green_openings_3.6.csv')\n",
    "intern_green_acc_lattice = lattice_from_csv(intern_green_acc_path)\n",
    "\n",
    "# loading the lattice from csv\n",
    "intern_facade_acc_path = os.path.relpath('../data/inner_facade_acces.csv')\n",
    "intern_facade_acc_lattice = lattice_from_csv(intern_facade_acc_path)\n",
    "\n",
    "# loading the lattice from csv\n",
    "ent6test_acc_path = os.path.relpath('../data/ent6test1.csv')\n",
    "ent6test_acc_lattice = lattice_from_csv(ent6test_acc_path)\n",
    "\n",
    "env_info_dict = {\n",
    "    #\"ent1_acces\": \"\" ,\n",
    "    #\"ent2_acces\": \"\" ,\n",
    "    #\"ent3_acces\": \"\" ,\n",
    "    #\"ent4_acces\": \"\" ,\n",
    "    #\"ent5_acces\": \"\" ,\n",
    "    #\"ent6_acces\": \"\" ,\n",
    "    #\"ent7_acces\": \"\" ,\n",
    "    #\"student_housing_acc\": \"\" ,\n",
    "    #\"assisted_living_acc\": \"\" ,\n",
    "    #\"starter_housing_acc\": \"\" ,\n",
    "    #\"restaurant_acc\": \"\" ,\n",
    "    #\"shop_acc\": \"\" ,\n",
    "    #\"cocooking_acc\": \"\" ,\n",
    "    #\"pub_acc\": \"\" ,\n",
    "    #\"gym_acc\": \"\" ,\n",
    "    #\"arcade_acc\": \"\" ,\n",
    "    #\"cinema_acc\": \"\" ,\n",
    "    #\"office_acc\": \"\" ,\n",
    "    #\"cowork_acc\": \"\" ,\n",
    "    #\"library_acc\": \"\" ,\n",
    "    #\"fablabs_acc\": \"\" ,\n",
    "    #\"catering_acc\": \"\" ,\n",
    "    #\"catering2_acc\": \"\" ,\n",
    "    #\"catering3_acc\": \"\" ,\n",
    "    #\"coffeehub_acc\": \"\" ,\n",
    "    #\"expandz\": \"\" ,\n",
    "    #\"vox_req\": \"\" ,\n",
    "    \"noise_acc\": noise_acc_lattice ,\n",
    "    #\"public_green_acc\": public_green_acc_lattice ,\n",
    "    #\"intern_green_acc\": intern_green_acc_lattice ,\n",
    "    #\"inner_facade_acc\": intern_facade_acc_lattice ,\n",
    "    \n",
    "}\n",
    "env_info_list = []\n",
    "env_info_dict_copy = env_info_dict. copy()\n",
    "env_info_list.append(env_info_dict_copy)\n",
    "env_info_base = copy.deepcopy(env_info_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5. Extract the connectivity graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the neighbours in the lattice\n",
    "def find_neighbours_masked(lattice, stencil, loc):\n",
    "    neigh_locs = np.argwhere(stencil) - stencil.origin + loc\n",
    "    neigh_filter = np.all(neigh_locs > -1, axis=1) * np.all(neigh_locs < np.array(lattice.shape), axis=1)\n",
    "    neigh_3d = neigh_locs[neigh_filter]\n",
    "    neigh_1d = [np.ravel_multi_index(n_loc, avail_lattice.shape) for n_loc in neigh_3d]\n",
    "    return(neigh_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the number of all voxels\n",
    "vox_count = avail_lattice.size \n",
    "\n",
    "# initialize the adjacency matrix\n",
    "adj_mtrx = np.zeros((vox_count,vox_count))\n",
    "\n",
    "# Finding the index of the available voxels in avail_lattice\n",
    "avail_index = np.array(np.where(avail_lattice == 1)).T\n",
    "\n",
    "# fill the adjacency matrix using the list of all neighbours\n",
    "for vox_loc in avail_index:\n",
    "    # find the 1D id\n",
    "    vox_id = np.ravel_multi_index(vox_loc, avail_lattice.shape)\n",
    "    # retrieve the list of neighbours of the voxel based on the stencil\n",
    "    vox_neighs = find_neighbours_masked(avail_lattice, stencil, loc = vox_loc)\n",
    "    # iterating over the neighbours\n",
    "    for neigh in vox_neighs:\n",
    "        # setting the entry to one\n",
    "        adj_mtrx[vox_id, neigh] = 1.0\n",
    "\n",
    "# construct the graph \n",
    "g = nx.from_numpy_array(adj_mtrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the adj matrix\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mtrx_loaded = pickle.load( open( \"../data/dist_mtrx.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Give the agents an optimal location\n",
    "\n",
    "### 1.1. Agent initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize the occupation lattice\n",
    "occ_lattice = avail_lattice * 0 - 1\n",
    "\n",
    "# Finding the index of the available voxels in avail_lattice\n",
    "avail_flat = avail_lattice.flatten()\n",
    "avail_index = np.array(np.where(avail_lattice == 1)).T\n",
    "\n",
    "# count the number of spaces (rows) and intiialize an agent for each space\n",
    "agn_num = len(agn_info)\n",
    "\n",
    "# adding the origins to the agents locations\n",
    "agn_locs = []\n",
    "\n",
    "# retrieving the entrance access value of the free neighbours\n",
    "for a_id in agn_ids:    \n",
    "    voxel_vals = []\n",
    "    pot_voxels = []\n",
    "    # retrieve agent preferences;\n",
    "    a_pref = agn_prefs[int(a_id)]\n",
    "    a_pref_dict = agn_info_df.loc[a_id]\n",
    "    # Voxel Evaluation Loop\n",
    "    for pot_vox in avail_index:\n",
    "        if avail_lattice[tuple(pot_vox)]:\n",
    "            \n",
    "            global_vox_value = 1.0\n",
    "            # for every lattice in the environment informations\n",
    "            for info_key, info_lattice in env_info_dict.items():\n",
    "                vox_val = info_lattice[tuple(pot_vox)]\n",
    "                print(vox_val)\n",
    "                # agn_vox_val = np.power(vox_val, a_pref[i])\n",
    "                agn_vox_val = np.power(vox_val, a_pref_dict[info_key])\n",
    "                global_vox_value *= agn_vox_val\n",
    "            # add the neighbour value to the list of values\n",
    "            voxel_vals.append(global_vox_value)\n",
    "            pot_voxels.append(pot_vox)\n",
    "        \n",
    "    # convert to numpy array\n",
    "    voxel_vals = np.array(voxel_vals)\n",
    "    # convert to numpy array\n",
    "    pot_voxels = np.array(pot_voxels)\n",
    "    # select the neighbour with highest value \n",
    "    selected_int = np.argmax(voxel_vals) \n",
    "    # find 3D intiger index of selected neighbour\n",
    "    selected_neigh_3d_id = tuple(pot_voxels[selected_int].T)\n",
    "    # find the location of the newly selected neighbour\n",
    "    selected_neigh_loc = np.array(selected_neigh_3d_id).flatten()\n",
    "\n",
    "    # add the newly selected neighbour location to agent locations\n",
    "    agn_locs.append([selected_neigh_loc])\n",
    "    # set the newly selected neighbour as UNavailable (0) in the availability lattice\n",
    "    avail_lattice[selected_neigh_3d_id] = 0\n",
    "    # set the newly selected neighbour as OCCUPIED by current agent \n",
    "    occ_lattice[selected_neigh_3d_id] = a_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_noise_lattice(agn_locs, avail_lattice):\n",
    "\n",
    "    # define the noise range\n",
    "    noise_range = [10.0, 60.0]\n",
    "    \n",
    "    # initialize noise sources\n",
    "    noise_src_points = []\n",
    "    noise_src_levels = []\n",
    "\n",
    "    # iterate over agents\n",
    "    for a_id in range(len(agn_locs)):\n",
    "        # extract agent locations\n",
    "        a_locs = agn_locs[a_id]\n",
    "        # retrieve the silent level of the agent\n",
    "        a_noise_level_mapped = 1 - agn_data.loc[a_id][\"silent_level\"]\n",
    "        # mapping the [0,1] values to noise level (db)\n",
    "        a_noise_level = a_noise_level_mapped * (noise_range[1] - noise_range[0]) + noise_range[0]\n",
    "\n",
    "        # for each agent location\n",
    "        for a_loc in a_locs:\n",
    "            # append the noise source information\n",
    "            noise_src_points.append(a_loc)\n",
    "            noise_src_levels.append(a_noise_level)\n",
    "\n",
    "    # convert to numpy array\n",
    "    noise_src_points = np.array(noise_src_points)\n",
    "\n",
    "    # create full lattice\n",
    "    full_lattice = avail_lattice * 0 + 1\n",
    "\n",
    "    # extract the coordiantes of the centroid of all voxel\n",
    "    vox_centroids = full_lattice.centroids\n",
    "\n",
    "    # extract voxel indices of all voxels\n",
    "    vox_indices = np.array(np.where(full_lattice==1)).T\n",
    "    \n",
    "    # initializing the sum lattice of noise\n",
    "    sum_noise_lats = avail_lattice * 0.0\n",
    "\n",
    "    # for each source of noise\n",
    "    for src_point, src_level in zip(noise_src_points,noise_src_levels):\n",
    "        # initialize the occupation lattice\n",
    "        dist_latice = avail_lattice * 0.0\n",
    "\n",
    "        for cen, ind in zip(vox_centroids, vox_indices):\n",
    "            # compute the euclidian distance\n",
    "            dist_latice[tuple(ind)] = sp.spatial.distance.euclidean(cen, src_point)\n",
    "\n",
    "        # computing the noise lattice from dist lattice\n",
    "        noise_latice = src_level - 20 * np.log10(dist_latice) - 8\n",
    "\n",
    "        # summing\n",
    "        sum_noise_lats += np.power(10, noise_latice / 10.0)\n",
    "\n",
    "    # computing the final aggregation\n",
    "    agg_noise_lats = 10 * np.log10(sum_noise_lats)\n",
    "    \n",
    "    # normalizing the noise values\n",
    "    normalized_silence_lattice = 1 - (agg_noise_lats - np.min(agg_noise_lats)) / (np.max(agg_noise_lats) - np.min(agg_noise_lats))\n",
    "\n",
    "    return normalized_silence_lattice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Visualizing the agents seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p = pv.Plotter(notebook=True)\n",
    "\n",
    "base_lattice = occ_lattice\n",
    "\n",
    "# Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data\n",
    "grid = pv.UniformGrid()\n",
    "grid.dimensions = np.array(base_lattice.shape) + 1\n",
    "# The bottom left corner of the data set\n",
    "grid.origin = base_lattice.minbound - base_lattice.unit * 0.5\n",
    "# These are the cell sizes along each axis\n",
    "grid.spacing = base_lattice.unit \n",
    "\n",
    "# adding the avilability lattice\n",
    "init_avail_lattice.fast_vis(p)\n",
    "\n",
    "\n",
    "# convert mesh to pv_mesh\n",
    "def tri_to_pv(tri_mesh):\n",
    "    faces = np.pad(tri_mesh.faces, ((0, 0),(1,0)), 'constant', constant_values=3)\n",
    "    pv_mesh = pv.PolyData(tri_mesh.vertices, faces)\n",
    "    return pv_mesh\n",
    "\n",
    "\n",
    "# adding the meshes\n",
    "p.add_mesh(tri_to_pv(immediate_context_mesh), color='#aaaaaa')\n",
    "\n",
    "# Add the data values to the cell data\n",
    "grid.cell_arrays[\"Agents\"] = base_lattice.flatten(order=\"F\").astype(int)  # Flatten the array!\n",
    "# filtering the voxels\n",
    "threshed = grid.threshold([-0.1, agn_num - 0.9])\n",
    "# adding the voxels\n",
    "p.add_mesh(threshed, name='sphere', show_edges=True, opacity=1.0, show_scalar_bar=False)\n",
    "\n",
    "\n",
    "# p.add_slider_widget(create_mesh, [0, n_frames], title='Time', value=0, event_type=\"always\", style=\"classic\", pointa=(0.1, 0.1), pointb=(0.9, 0.1))\n",
    "p.show(use_ipyvtk=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creation of vertical shaft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Manually set cluster center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually set cluster centers\n",
    "cluster_center_manual = { \n",
    "    0: [[10,12,1]],    \n",
    "    1: [[23,18,1]],    \n",
    "    2: [[35,10,1]],    \n",
    "    3: [[13,6,1]],\n",
    "    4: [[21,6,1]], \n",
    "    5: [[19,12,1]],\n",
    "    6: [[35,4,1]],\n",
    "    7: [[35,17,1]],\n",
    "    \n",
    "}\n",
    "\n",
    "cluster_center_0 = cluster_center_manual[0]\n",
    "cluster_center_1 = cluster_center_manual[1]\n",
    "cluster_center_2 = cluster_center_manual[2]\n",
    "cluster_center_3 = cluster_center_manual[3]\n",
    "cluster_center_4 = cluster_center_manual[4]\n",
    "cluster_center_5 = cluster_center_manual[5]\n",
    "cluster_center_6 = cluster_center_manual[6]\n",
    "cluster_center_7 = cluster_center_manual[7]\n",
    "\n",
    "cluster_center = cluster_center_0 + cluster_center_1 + cluster_center_2 + cluster_center_3 + cluster_center_4  + cluster_center_5 + cluster_center_6 + cluster_center_7 #+ cluster_center_8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let the cluster center go in the z direction\n",
    "shft_lattice = occ_lattice * 0\n",
    "for cl_cen in cluster_center:\n",
    "    shft_lattice[cl_cen[0],cl_cen[1],:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shft_lattice *= init_avail_lattice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Visualize Vertical Shafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lattice = shft_lattice\n",
    "\n",
    "# Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data\n",
    "grid = pv.UniformGrid()\n",
    "grid.dimensions = np.array(base_lattice.shape) + 1\n",
    "# The bottom left corner of the data set\n",
    "grid.origin = base_lattice.minbound - base_lattice.unit * 0.5\n",
    "# These are the cell sizes along each axis\n",
    "grid.spacing = base_lattice.unit \n",
    "\n",
    "# adding the avilability lattice\n",
    "init_avail_lattice.fast_vis(p)\n",
    "\n",
    "# convert mesh to pv_mesh\n",
    "def tri_to_pv(tri_mesh):\n",
    "    faces = np.pad(tri_mesh.faces, ((0, 0),(1,0)), 'constant', constant_values=3)\n",
    "    pv_mesh = pv.PolyData(tri_mesh.vertices, faces)\n",
    "    return pv_mesh\n",
    "\n",
    "\n",
    "# adding the meshes\n",
    "p.add_mesh(tri_to_pv(immediate_context_mesh), style = 'surface')\n",
    "\n",
    "\n",
    "# Add the data values to the cell data\n",
    "grid.cell_arrays[\"Agents\"] = base_lattice.flatten(order=\"F\").astype(int)  # Flatten the array!\n",
    "# filtering the voxels\n",
    "threshed = grid.threshold([0.9, 1.1])\n",
    "# adding the voxels\n",
    "p.add_mesh(threshed, name='sphere', show_edges=True, opacity=1.0, show_scalar_bar=False)\n",
    "\n",
    "\n",
    "p.show(use_ipyvtk=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creation of Horizontal Corridors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Extract the connectivity graph from the lattice based on the horizontal stencil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the connectivity graph of the envelope lattice\n",
    "def find_neighbours_masked(lattice, stencil, loc):\n",
    "    neigh_locs = np.argwhere(stencil) - stencil.origin + loc\n",
    "    neigh_filter = np.all(neigh_locs > -1, axis=1) * np.all(neigh_locs < np.array(lattice.shape), axis=1)\n",
    "    neigh_3d = neigh_locs[neigh_filter]\n",
    "    neigh_1d = [np.ravel_multi_index(n_loc, avail_lattice.shape) for n_loc in neigh_3d]\n",
    "    return(neigh_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the number of all voxels\n",
    "vox_count = avail_lattice.size \n",
    "\n",
    "# initialize the adjacency matrix\n",
    "adj_mtrx = np.zeros((vox_count,vox_count))\n",
    "\n",
    "# Finding the index of the available voxels in avail_lattice\n",
    "avail_index = np.array(np.where(avail_lattice == 1)).T\n",
    "\n",
    "# fill the adjacency matrix using the list of all neighbours\n",
    "for vox_loc in avail_index:\n",
    "    # find the 1D id\n",
    "    vox_id = np.ravel_multi_index(vox_loc, avail_lattice.shape)\n",
    "    # retrieve the list of neighbours of the voxel based on the stencil\n",
    "    vox_neighs = find_neighbours_masked(init_avail_lattice, stencil, loc = vox_loc)\n",
    "    # iterating over the neighbours\n",
    "    for neigh in vox_neighs:\n",
    "        # setting the entry to one\n",
    "        adj_mtrx[vox_id, neigh] = 1.0\n",
    "\n",
    "# construct the graph \n",
    "g = nx.from_numpy_array(adj_mtrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_ind = np.array(np.where(occ_lattice > -1)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Find the shortest path between an agent and a shaft and construct the corridor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize corridor lattice\n",
    "cor_lattice = shft_lattice * 0\n",
    "cor_flat = cor_lattice.flatten()\n",
    "# for each voxel that needs to have access to shafts\n",
    "for a_vox in occ_ind:\n",
    "    \n",
    "    # slice the corridor lattice horizontally\n",
    "    # add the previously created corridors as competing destination to shafts \n",
    "    cor_floor = shft_lattice[:,:,a_vox[2]] + cor_lattice[:,:,a_vox[2]]\n",
    "    # find the vertical shaft voxel indices\n",
    "    shaft_vox_inds = np.array(np.where(cor_floor > 0)).T\n",
    "    paths = []\n",
    "    path_lens = []\n",
    "    for shft_ind in shaft_vox_inds:\n",
    "        # construct the destination address\n",
    "        dst_vox = np.array([shft_ind[0],shft_ind[1],a_vox[2]])\n",
    "        # construct 1-dimensional indices\n",
    "        src_ind = np.ravel_multi_index(a_vox, shft_lattice.shape)\n",
    "        dst_ind = np.ravel_multi_index(dst_vox, shft_lattice.shape)\n",
    "        \n",
    "       \n",
    "        \n",
    "        # find the shortest path\n",
    "        try:\n",
    "            path = nx.algorithms.shortest_paths.astar.astar_path(g, src_ind, dst_ind)\n",
    "            paths.append(path)\n",
    "            path_lens.append(len(path))\n",
    "        except:\n",
    "            print(\"disconnected:\", a_vox, init_avail_lattice[tuple(a_vox)], dst_vox, init_avail_lattice[tuple(dst_vox)])\n",
    "\n",
    "    \n",
    "    path_order = np.array(path_lens).argsort()\n",
    "    if len(paths) > 0:\n",
    "        shortest_path = paths[path_order[0]]\n",
    "        # set the shortest path occupied in the \n",
    "        cor_flat[shortest_path] = 1\n",
    "       \n",
    "    # reshape the flat lattice\n",
    "    cor_lattice = cor_flat.reshape(cor_lattice.shape)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Find the shortest paths between the shafts on the ground floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the shortest path between them \n",
    "cor_lattice2 = shft_lattice * 0\n",
    "\n",
    "# initialize corridor lattice\n",
    "cor_flat = cor_lattice2.flatten()\n",
    "\n",
    "# slice the corridorlattice horizontally (same z value)\n",
    "cor_floor = shft_lattice[:,:,1] + cor_lattice[:,:,a_vox[2]]\n",
    "# find the vertical shaft voxel indices\n",
    "shaft_vox_inds = np.array(np.where(cor_floor > 0)).T\n",
    "\n",
    "# for each voxel that needs to have access to shafts\n",
    "for src_shft_ind in shaft_vox_inds:\n",
    "    \n",
    "    #find the distance and the path to every other shaft \n",
    "    paths = []\n",
    "    path_lens = []\n",
    "    \n",
    "    for dst_shft_ind in shaft_vox_inds:\n",
    "        # construct the destination address\n",
    "        src_vox = np.array([src_shft_ind[0],src_shft_ind[1],0])\n",
    "        dst_vox = np.array([dst_shft_ind[0],dst_shft_ind[1],0])\n",
    "        # construct 1-dimensional indices\n",
    "        src_ind = np.ravel_multi_index(src_vox, shft_lattice.shape)\n",
    "        dst_ind = np.ravel_multi_index(dst_vox, shft_lattice.shape)\n",
    "                  \n",
    "        try:\n",
    "            path = nx.algorithms.shortest_paths.astar.astar_path(g, src_ind, dst_ind)\n",
    "            #regel hieronder \n",
    "            if len(path) > 1:\n",
    "                paths.append(path)\n",
    "                path_lens.append(len(path))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    path_order = np.array(path_lens).argsort()\n",
    "    if len(paths) > 0:\n",
    "        shortest_path = paths[path_order[0]]\n",
    "        cor_flat[shortest_path] = 1\n",
    "\n",
    "    if len(paths) > 1:\n",
    "        snd_shortest_path = paths[path_order[1]]\n",
    "        cor_flat[snd_shortest_path] = 1            \n",
    "            \n",
    "    cor_lattice2 = cor_flat.reshape(cor_lattice2.shape)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Find the shortest paths between the shafts on the third floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1. Extract the connectivity graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the connectivity graph of the full envelope\n",
    "def find_neighbours_masked(lattice, stencil, loc):\n",
    "    neigh_locs = np.argwhere(stencil) - stencil.origin + loc\n",
    "    neigh_filter = np.all(neigh_locs > -1, axis=1) * np.all(neigh_locs < np.array(lattice.shape), axis=1)\n",
    "    neigh_3d = neigh_locs[neigh_filter]\n",
    "    neigh_1d = [np.ravel_multi_index(n_loc, full_lattice.shape) for n_loc in neigh_3d]\n",
    "    return(neigh_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the number of all voxels\n",
    "vox_count = full_lattice.size \n",
    "\n",
    "# initialize the adjacency matrix\n",
    "adj_mtrx = np.zeros((vox_count,vox_count))\n",
    "\n",
    "# Finding the index of the available voxels in avail_lattice\n",
    "full_index = np.array(np.where(full_lattice == 1)).T\n",
    "\n",
    "# fill the adjacency matrix using the list of all neighbours\n",
    "for vox_loc in full_index:\n",
    "    # find the 1D id\n",
    "    vox_id = np.ravel_multi_index(vox_loc, full_lattice.shape)\n",
    "    # retrieve the list of neighbours of the voxel based on the stencil\n",
    "    vox_neighs = find_neighbours_masked(init_full_lattice, stencil, loc = vox_loc)\n",
    "    # iterating over the neighbours\n",
    "    for neigh in vox_neighs:\n",
    "        # setting the entry to one\n",
    "        adj_mtrx[vox_id, neigh] = 1.0\n",
    "\n",
    "# construct the graph \n",
    "g = nx.from_numpy_array(adj_mtrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_ind = np.array(np.where(occ_lattice > -1)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Find the shortest path and create the corridors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the shortest path between them \n",
    "cor_lattice3 = shft_lattice * 0\n",
    "\n",
    "# initialize corridor lattice\n",
    "cor_flat = cor_lattice3.flatten()\n",
    "\n",
    "# slice the corridorlattice horizontally (same z value)\n",
    "cor_floor = shft_lattice[:,:,1] + cor_lattice3[:,:,a_vox[2]]\n",
    "# find the vertical shaft voxel indices\n",
    "shaft_vox_inds = np.array(np.where(cor_floor > 0)).T\n",
    "\n",
    "# for each voxel that needs to have access to shafts\n",
    "for src_shft_ind in shaft_vox_inds:\n",
    "    \n",
    "    #find the distance and the path to every other shaft \n",
    "    paths = []\n",
    "    path_lens = []\n",
    "    \n",
    "    for dst_shft_ind in shaft_vox_inds:\n",
    "        # construct the destination address\n",
    "        src_vox = np.array([src_shft_ind[0],src_shft_ind[1],3])\n",
    "        dst_vox = np.array([dst_shft_ind[0],dst_shft_ind[1],3])\n",
    "        # construct 1-dimensional indices\n",
    "        src_ind = np.ravel_multi_index(src_vox, shft_lattice.shape)\n",
    "        dst_ind = np.ravel_multi_index(dst_vox, shft_lattice.shape)\n",
    "        \n",
    "              \n",
    "        try:\n",
    "            path = nx.algorithms.shortest_paths.astar.astar_path(g, src_ind, dst_ind)\n",
    "            #regel hieronder \n",
    "            if len(path) > 1:\n",
    "                paths.append(path)\n",
    "                path_lens.append(len(path))\n",
    "        except:\n",
    "            pass\n",
    "            #print(\"disconnected:\", a_vox, init_avail_lattice[tuple(a_vox)], dst_vox, init_avail_lattice[tuple(dst_vox)])\n",
    "\n",
    "    path_order = np.array(path_lens).argsort()\n",
    "    if len(paths) > 0:\n",
    "        shortest_path = paths[path_order[0]]\n",
    "        # set the shortest path occupied in the \n",
    "        cor_flat[shortest_path] = 1\n",
    "    if len(paths) > 1:\n",
    "        snd_shortest_path = paths[path_order[1]]\n",
    "        cor_flat[snd_shortest_path] = 1\n",
    "  \n",
    "            \n",
    "    cor_lattice3 = cor_flat.reshape(cor_lattice3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lattice = shft_lattice + cor_lattice + cor_lattice2 + cor_lattice3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Visualize the accessability lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p = pv.Plotter(notebook=True)\n",
    "\n",
    "base_lattice = final_lattice\n",
    "\n",
    "# Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data\n",
    "grid = pv.UniformGrid()\n",
    "grid.dimensions = np.array(base_lattice.shape) + 1\n",
    "# The bottom left corner of the data set\n",
    "grid.origin = base_lattice.minbound - base_lattice.unit * 0.5\n",
    "# These are the cell sizes along each axis\n",
    "grid.spacing = base_lattice.unit \n",
    "\n",
    "\n",
    "# adding the avilability lattice\n",
    "#avail_lattice.fast_vis(p)\n",
    "\n",
    "\n",
    "# convert mesh to pv_mesh\n",
    "def tri_to_pv(tri_mesh):\n",
    "    faces = np.pad(tri_mesh.faces, ((0, 0),(1,0)), 'constant', constant_values=3)\n",
    "    pv_mesh = pv.PolyData(tri_mesh.vertices, faces)\n",
    "    return pv_mesh\n",
    "\n",
    "\n",
    "# adding the meshes\n",
    "p.add_mesh(tri_to_pv(immediate_context_mesh), style = 'surface')\n",
    "\n",
    "\n",
    "# Add the data values to the cell data\n",
    "grid.cell_arrays[\"Agents\"] = base_lattice.flatten(order=\"F\").astype(int)  # Flatten the array!\n",
    "\n",
    "# filtering the voxels\n",
    "threshed = grid.threshold([0.9, 2.1])\n",
    "\n",
    "# adding the voxels\n",
    "p.add_mesh(threshed, name='sphere', show_edges=True, opacity=1.0, show_scalar_bar=False, cmap=\"tab20\")\n",
    "\n",
    "p.show(use_ipyvtk=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the corridor lattice as a csv\n",
    "csv_path = os.path.relpath('../data/corridors_bridges_new.csv')\n",
    "final_lattice.to_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Shervin Azadi and Pirouz Nourian\"\n",
    "__changes_made_by__ = \"Lotte Zwolsman\"\n",
    "__license__ = \"MIT\"\n",
    "__version__ = \"1.0\"\n",
    "__url__ = \"https://github.com/frankvahstal/spatial_computing_workshops\"\n",
    "__summary__ = \"Spatial Computing Design Studio Workshop on Path Finding and Corridorfor Generative Spatial Relations\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}