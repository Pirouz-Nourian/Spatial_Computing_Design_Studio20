{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed Allocation and agent growth\n",
    "\n",
    "[More about seed allocation](/spatial_computing_project_template/A3_Massing/Products/Seed%20allocation/Seed%20allocation/)\n",
    "\n",
    "\n",
    "[More about agent growth](/spatial_computing_project_template/A3_Massing/Products/Agent%20growth/Agent%20growth/)\n",
    "\n",
    "In this notebook, we will first place the agents in an optimal voxel. We will do this by importing all of the previously computed lattices. When the agents have taken their place, they will grow in a specific direction and size. \n",
    "\n",
    "The inputs needed for this notebook are the previously computed lattices, the program csv and the voxelized final envelope. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initialization\n",
    "\n",
    "### 0.1. Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import topogenesis as tg\n",
    "import pyvista as pv\n",
    "import trimesh as tm\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import copy\n",
    "import scipy as sp\n",
    "np.random.seed(0)\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra import function\n",
    "def lattice_from_csv(file_path):\n",
    "    # read metadata\n",
    "    meta_df = pd.read_csv(file_path, nrows=3)\n",
    "\n",
    "    shape = np.array(meta_df['shape'])\n",
    "    unit = np.array(meta_df['unit'])\n",
    "    minbound = np.array(meta_df['minbound'])\n",
    "\n",
    "    # read lattice\n",
    "    lattice_df = pd.read_csv(file_path, skiprows=5)\n",
    "\n",
    "    # create the buffer\n",
    "    buffer = np.array(lattice_df['value']).reshape(shape)\n",
    "\n",
    "    # create the lattice\n",
    "    l = tg.to_lattice(buffer, minbound=minbound, unit=unit)\n",
    "\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Define the Neighborhood (Stencil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating neighborhood definition\n",
    "stencil = tg.create_stencil(\"von_neumann\", 1, 1)\n",
    "# setting the center to zero\n",
    "stencil.set_index([0, 0, 0], 0)\n",
    "\n",
    "# creating neighborhood definition - center with 0 neighbours in xy plane\n",
    "s_z = tg.create_stencil(\"von_neumann\", 0, 1)\n",
    "# setting the center to zero\n",
    "s_z.set_index([0, 0, 0], 0)\n",
    "# setting z neighbours to 1\n",
    "s_z.set_index([0, 0,-1], 1)\n",
    "s_z.set_index([0, 0, 1], 1)\n",
    "\n",
    "# creating neighborhood definition - center with 0 neighbours in z plane\n",
    "s_xy = tg.create_stencil(\"von_neumann\", 1, 1)\n",
    "# setting the center to zero\n",
    "s_xy.set_index([0, 0, 0], 0)\n",
    "# setting z neighbours to 0\n",
    "s_xy.set_index([0, 0, 1], 0)\n",
    "s_xy.set_index([0, 0, -1], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3. Load the envelope lattice as the avialbility lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the lattice from csv\n",
    "context_path = os.path.relpath('../data/immediate_context.obj')\n",
    "context_mesh = tm.load(context_path)\n",
    "\n",
    "lattice_path = os.path.relpath('../data/final_envelope_new.csv')\n",
    "avail_lattice = lattice_from_csv(lattice_path)\n",
    "new_avail_lattice = (avail_lattice + 0.499) > 0.5\n",
    "\n",
    "init_avail_lattice = tg.to_lattice(np.copy(avail_lattice), avail_lattice) \n",
    "new_init_avail_lattice = tg.to_lattice(np.copy(new_avail_lattice), new_avail_lattice) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the voxelized envelope\n",
    "# convert trimesh to pv_mesh\n",
    "def tri_to_pv(tri_mesh):\n",
    "    faces = np.pad(tri_mesh.faces, ((0, 0),(1,0)), 'constant', constant_values=3)\n",
    "    pv_mesh = pv.PolyData(tri_mesh.vertices, faces)\n",
    "    return pv_mesh\n",
    "\n",
    "# initiating the plotter\n",
    "p = pv.Plotter(notebook=True)\n",
    "\n",
    "# fast visualization of the lattice\n",
    "new_avail_lattice.fast_vis(p) \n",
    "\n",
    "# plotting\n",
    "p.show(use_ipyvtk=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4. Load Agents Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading program (agents information) from CSV\n",
    "# The program hase some extra collums, created for future expansion of the criteria of allocation and growth.\n",
    "# We haven't been able to finish the implementation of those criteria: \n",
    "prgm_path = os.path.relpath('../data/program.csv')\n",
    "\n",
    "# start reading information after the first column and after the first row\n",
    "agn_info = np.genfromtxt(prgm_path, delimiter=',')[1:, 1:]\n",
    "\n",
    "# extract agent ids\n",
    "agn_ids = agn_info[:, 0]\n",
    "\n",
    "# extract agent preference to expand in the z-direction\n",
    "agn_expandz = agn_info[:, 38]\n",
    "\n",
    "# extract maximum voxels of each agent agent. This represents the maximum area & volume\n",
    "agn_vox_req = agn_info[:, 39]\n",
    "\n",
    "# extract criteria for silent level and noise repel \n",
    "agn_silent_level = agn_info[:, 43]\n",
    "agn_noise_repel = agn_info[:, 44]\n",
    "\n",
    "# read the program with the use of panda's to create a dict. This is usefull to extract the right criteria for the right lattices. \n",
    "agn_info_df = pd.read_csv('../data/program.csv') \n",
    "agn_data = pd.read_csv(prgm_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5. Initialize environment information layers from Sun Access Lattice and Entrance Access Lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the lattice from csv\n",
    "sun_acc_path = os.path.relpath('../data/sun_access_highres.csv')\n",
    "sun_acc_lattice = lattice_from_csv(sun_acc_path)\n",
    "\n",
    "ent1_acc_path = os.path.relpath('../data/ent1_access.csv')\n",
    "ent1_acc_lattice = lattice_from_csv(ent1_acc_path)\n",
    "\n",
    "ent2_acc_path = os.path.relpath('../data/ent2_access.csv')\n",
    "ent2_acc_lattice = lattice_from_csv(ent2_acc_path)\n",
    "\n",
    "ent3_1_acc_path = os.path.relpath('../data/ent3.1_access.csv')\n",
    "ent3_1_acc_lattice = lattice_from_csv(ent3_1_acc_path)\n",
    "\n",
    "ent3_2_acc_path = os.path.relpath('../data/ent3.2_access.csv')\n",
    "ent3_2_acc_lattice = lattice_from_csv(ent3_2_acc_path)\n",
    "\n",
    "ent3_3_acc_path = os.path.relpath('../data/ent3.3_access.csv')\n",
    "ent3_3_acc_lattice = lattice_from_csv(ent3_3_acc_path)\n",
    "\n",
    "ent4_acc_path = os.path.relpath('../data/ent4_access.csv')\n",
    "ent4_acc_lattice = lattice_from_csv(ent4_acc_path)\n",
    "\n",
    "ent5_acc_path = os.path.relpath('../data/ent5_access.csv')\n",
    "ent5_acc_lattice = lattice_from_csv(ent5_acc_path)\n",
    "\n",
    "ent6_acc_path = os.path.relpath('../data/ent6_access.csv')\n",
    "ent6_acc_lattice = lattice_from_csv(ent6_acc_path)\n",
    "\n",
    "ent7_acc_path = os.path.relpath('../data/ent7_access.csv')\n",
    "ent7_acc_lattice = lattice_from_csv(ent7_acc_path)\n",
    "\n",
    "noise_acc_path = os.path.relpath('../data/HeerBokelweg_noise.csv')\n",
    "noise_acc_lattice = lattice_from_csv(noise_acc_path)[:41, :21, :11]\n",
    "\n",
    "public_green_acc_path = os.path.relpath('../data/public_greenery_highres.csv')\n",
    "public_green_acc_lattice = lattice_from_csv(public_green_acc_path)\n",
    "\n",
    "# this would be a lattice for the green corridor on the ground floor\n",
    "# intern_green_acc_path = os.path.relpath('../data/green_openings_3.6.csv')\n",
    "# intern_green_acc_lattice = lattice_from_csv(intern_green_acc_path)\n",
    "\n",
    "# this would be a lattice to have functions attract to a facade facing the green corridor\n",
    "# intern_facade_acc_path = os.path.relpath('../data/inner_facade_acces.csv')\n",
    "# intern_facade_acc_lattice = lattice_from_csv(intern_facade_acc_path)\n",
    "\n",
    "env_info_dict = {\n",
    "    \"ent1_acc\": ent1_acc_lattice ,\n",
    "    \"ent2_acc\": ent2_acc_lattice ,\n",
    "    \"ent3.1_acc\": ent3_1_acc_lattice ,\n",
    "    \"ent3.2_acc\": ent3_2_acc_lattice ,\n",
    "    \"ent3.3_acc\": ent3_3_acc_lattice ,\n",
    "    \"ent4_acc\": ent4_acc_lattice ,\n",
    "    \"ent5_acc\": ent5_acc_lattice ,\n",
    "    \"ent6_acc\": ent6_acc_lattice ,\n",
    "    \"ent7_acc\": ent7_acc_lattice ,\n",
    "    \"sun_acc\": sun_acc_lattice ,\n",
    "    \"noise_acc\": noise_acc_lattice ,\n",
    "    \"public_green_acc\": public_green_acc_lattice ,\n",
    "    #\"intern_green_acc\": intern_green_acc_lattice ,\n",
    "    #\"inner_facade_acc\": intern_facade_acc_lattice \n",
    "    \n",
    "}\n",
    "env_info_list = []\n",
    "env_info_dict_copy = env_info_dict. copy()\n",
    "env_info_list.append(env_info_dict_copy)\n",
    "env_info_base = copy.deepcopy(env_info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the info lattices\n",
    "p = pv.Plotter(notebook=True)\n",
    "\n",
    "info_val_list = list(env_info_dict.values())\n",
    "info_key_list = env_info_dict.keys()\n",
    "for i, k in enumerate(info_key_list):\n",
    "    print(i, k)\n",
    "\n",
    "base_lattice = info_val_list[0]\n",
    "\n",
    "# Create the spatial reference\n",
    "grid = pv.UniformGrid()\n",
    "\n",
    "# Set the grid dimensions: shape because we want to inject our values\n",
    "grid.dimensions = base_lattice.shape\n",
    "# The bottom left corner of the data set\n",
    "grid.origin = base_lattice.minbound\n",
    "# These are the cell sizes along each axis\n",
    "grid.spacing = base_lattice.unit\n",
    "\n",
    "p.add_mesh(tri_to_pv(context_mesh), style='surface')\n",
    "\n",
    "def create_mesh(value):\n",
    "    f = int(value)\n",
    "    lattice = info_val_list[f]\n",
    "\n",
    "    # Add the data values to the cell data\n",
    "    grid.point_arrays[\"info\"] = lattice.flatten(order=\"F\")  # Flatten the Lattice\n",
    "        \n",
    "    # adding the volume\n",
    "    opacity = np.array([0,0.6,0.6,0.6,0.6,0.6,0.6])*1.5\n",
    "    p.add_volume(grid, cmap=\"coolwarm\", name='sphere', clim=[0.0, 1.0],opacity=opacity, shade=True)\n",
    "\n",
    "    return\n",
    "\n",
    "p.add_slider_widget(create_mesh, [0, len(info_val_list)-1], title='Time', value=0, event_type=\"always\", style=\"classic\", pointa=(0.1, 0.1), pointb=(0.9, 0.1))\n",
    "p.show(use_ipyvtk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the number of all voxels\n",
    "vox_count = new_avail_lattice.size \n",
    "\n",
    "# initialize the adjacency matrix\n",
    "adj_mtrx = np.zeros((vox_count,vox_count))\n",
    "\n",
    "# Finding the index of the available voxels in avail_lattice\n",
    "avail_index = np.array(np.where(new_avail_lattice == 1)).T\n",
    "\n",
    "# fill the adjacency matrix using the list of all neighbours\n",
    "for vox_loc in avail_index:\n",
    "    # find the 1D id\n",
    "    vox_id = np.ravel_multi_index(vox_loc, new_avail_lattice.shape)\n",
    "    # retrieve the list of neighbours of the voxel based on the stencil\n",
    "    vox_neighs = new_avail_lattice.find_neighbours_masked(stencil, loc = vox_loc)\n",
    "    # iterating over the neighbours\n",
    "    for neigh in vox_neighs:\n",
    "        # setting the entry to one\n",
    "        adj_mtrx[vox_id, neigh] = 1.0\n",
    "\n",
    "# construct the graph \n",
    "g = nx.from_numpy_array(adj_mtrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the distance of all voxels to all voxels using floyd warshal algorithm#\n",
    "# this will be done once to save computation time, therefore the next line is commented. When the envelope changes, the caluclation has to be done again\n",
    "\n",
    "# dist_mtrx = nx.floyd_warshall_numpy(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will save the calculated dist_mtrx. Again this will be done once since we calculate the dist_mtrx once.\n",
    "\n",
    "# pickle.dump(dist_mtrx, open( \"../data/dist_mtrx_final.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the saved dist_mtrx is loaded in a variable to use\n",
    "dist_mtrx_loaded = pickle.load( open( \"../data/dist_mtrx_final.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ABM Simulation\n",
    "\n",
    "### 1.1. Initialize the Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the occupation lattice\n",
    "occ_lattice = new_avail_lattice * 0 - 1\n",
    "\n",
    "# Finding the index of the available voxels in avail_lattice\n",
    "avail_flat = new_avail_lattice.flatten()\n",
    "avail_index = np.array(np.where(new_avail_lattice == 1)).T\n",
    "\n",
    "# count the number of spaces (rows) and intiialize an agent for each space\n",
    "agn_num = len(agn_info)\n",
    "\n",
    "# adding the origins to the agents locations\n",
    "agn_locs = []\n",
    "# retrieving the entrance access value of the free neighbours\n",
    "for a_id in agn_ids:    \n",
    "    voxel_vals = []\n",
    "    pot_voxels = []\n",
    "    \n",
    "    # retrieve agent preferences;\n",
    "    a_pref_dict = agn_info_df.loc[a_id]\n",
    "    \n",
    "    # Voxel Evaluation Loop\n",
    "    for pot_vox in avail_index:\n",
    "        if new_avail_lattice[tuple(pot_vox)]:\n",
    "            \n",
    "            global_vox_value = 1.0\n",
    "            # for every lattice in the environment informations\n",
    "            for info_key, info_lattice in env_info_dict.items():\n",
    "                # Here we utilise Fuzzy Logics to be able to compare different layers \n",
    "                # of environmental information and evaluate the voxel for the agent. \n",
    "                vox_val = info_lattice[tuple(pot_vox)]\n",
    "                # agn_vox_val = np.power(vox_val, a_pref[i])\n",
    "                agn_vox_val = np.power(vox_val, a_pref_dict[info_key])\n",
    "                global_vox_value *= agn_vox_val\n",
    "            # add the neighbour value to the list of values\n",
    "            voxel_vals.append(global_vox_value)\n",
    "            pot_voxels.append(pot_vox)\n",
    "        \n",
    "    # convert to numpy array\n",
    "    voxel_vals = np.array(voxel_vals)\n",
    "    # convert to numpy array\n",
    "    pot_voxels = np.array(pot_voxels)\n",
    "    # select the neighbour with highest value \n",
    "    selected_int = np.argmax(voxel_vals) \n",
    "    # find 3D intiger index of selected neighbour\n",
    "    selected_neigh_3d_id = tuple(pot_voxels[selected_int].T)\n",
    "    # find the location of the newly selected neighbour\n",
    "    selected_neigh_loc = np.array(selected_neigh_3d_id).flatten()\n",
    "\n",
    "    # add the newly selected neighbour location to agent locations\n",
    "    agn_locs.append([selected_neigh_loc])\n",
    "    # set the newly selected neighbour as UNavailable (0) in the availability lattice\n",
    "    new_avail_lattice[selected_neigh_3d_id] = 0\n",
    "    # set the newly selected neighbour as OCCUPIED by current agent \n",
    "    # (-1 means not-occupied so a_id)\n",
    "    occ_lattice[selected_neigh_3d_id] = a_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_noise_lattice(agn_locs, new_avail_lattice):\n",
    "\n",
    "    # define the noise range\n",
    "    noise_range = [10.0, 60.0]\n",
    "    \n",
    "    # initialize noise sources\n",
    "    noise_src_points = []\n",
    "    noise_src_levels = []\n",
    "\n",
    "    # iterate over agents\n",
    "    for a_id in range(len(agn_locs)):\n",
    "        # extract agent locations\n",
    "        a_locs = agn_locs[a_id]\n",
    "        # retrieve the silent level of the agent\n",
    "        a_noise_level_mapped = 1 - agn_data.loc[a_id][\"silent_level\"]\n",
    "        # mapping the [0,1] values to noise level (db)\n",
    "        a_noise_level = a_noise_level_mapped * (noise_range[1] - noise_range[0]) + noise_range[0]\n",
    "\n",
    "        # for each agent location\n",
    "        for a_loc in a_locs:\n",
    "            # append the noise source information\n",
    "            noise_src_points.append(a_loc)\n",
    "            noise_src_levels.append(a_noise_level)\n",
    "\n",
    "    # convert to numpy array\n",
    "    noise_src_points = np.array(noise_src_points)\n",
    "\n",
    "    # create full lattice\n",
    "    full_lattice = new_avail_lattice * 0 + 1\n",
    "\n",
    "    # extract the coordiantes of the centroid of all voxel\n",
    "    vox_centroids = full_lattice.centroids\n",
    "\n",
    "    # extract voxel indices of all voxels\n",
    "    vox_indices = np.array(np.where(full_lattice==1)).T\n",
    "    \n",
    "    # initializing the sum lattice of noise\n",
    "    sum_noise_lats = new_avail_lattice * 0.0\n",
    "\n",
    "    # for each source of noise\n",
    "    for src_point, src_level in zip(noise_src_points,noise_src_levels):\n",
    "        # initialize the occupation lattice\n",
    "        dist_latice = new_avail_lattice * 0.0\n",
    "\n",
    "        for cen, ind in zip(vox_centroids, vox_indices):\n",
    "            # compute the euclidian distance\n",
    "            dist_latice[tuple(ind)] = sp.spatial.distance.euclidean(cen, src_point)\n",
    "\n",
    "        # computing the noise lattice from dist lattice\n",
    "        noise_latice = src_level - 20 * np.log10(dist_latice) - 8\n",
    "\n",
    "        # summing\n",
    "        sum_noise_lats += np.power(10, noise_latice / 10.0)\n",
    "\n",
    "    # computing the final aggregation\n",
    "    agg_noise_lats = 10 * np.log10(sum_noise_lats)\n",
    "    \n",
    "    # normalizing the noise values\n",
    "    normalized_silence_lattice = 1 - (agg_noise_lats - np.min(agg_noise_lats)) / (np.max(agg_noise_lats) - np.min(agg_noise_lats))\n",
    "\n",
    "    return normalized_silence_lattice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Running the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_info = {\"noise_repel\": dynamic_noise_lattice}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make a deep copy of occupation lattice\n",
    "cur_occ_lattice = tg.to_lattice(np.copy(occ_lattice), occ_lattice)\n",
    "# initialzing the list of frames\n",
    "frames = [cur_occ_lattice]\n",
    "\n",
    "# setting the time variable to 0\n",
    "t = 0\n",
    "# choosing the number of frames. Our maximum of voxels is 620, therefore if you want to see the full growth choose 620.\n",
    "# 620 frames takes a while to calculate, choose something around 10 to quick test the code\n",
    "n_frames = 620\n",
    "\n",
    "# Simulation Loop\n",
    "# main feedback loop of the simulation (for each time step ...)\n",
    "while t<n_frames:\n",
    "    \n",
    "    # this lets functions repel each other. This does take very long to calculate. \n",
    "    # for info_key, info_function in dynamic_info.items():\n",
    "        # env_info_dict[info_key] = info_function(agn_locs, avail_lattice)\n",
    "    \n",
    "    # this part is about the dynamic relations\n",
    "    agn_acc_list = []\n",
    "    # for each agent\n",
    "    for a_id in range(agn_num):\n",
    "        # find which voxel occupied by destination function (roof garden) \n",
    "        a_locs = agn_locs[a_id]\n",
    "        # organize 3d indices vertically\n",
    "        a_locs_array = np.array(a_locs).T\n",
    "        # extract 1d index for all the locations of this agent\n",
    "        a_locs_1d = np.ravel_multi_index(a_locs_array, new_avail_lattice.shape)\n",
    "\n",
    "        # extract distance field to those voxels from the distance matrix \n",
    "        voxel_dists = dist_mtrx_loaded[a_locs_1d]\n",
    "\n",
    "        # combine dist fields of all voxels of this agent\n",
    "        combined_dists = voxel_dists.min(axis=0)\n",
    "        max_valid = np.ma.masked_invalid(combined_dists).max()\n",
    "        # set the infinities to one more than the maximum valid values\n",
    "        combined_dists[combined_dists == np.inf] = max_valid + 1\n",
    "        # mapping the values from (0, max) to (1, 0)\n",
    "        mapped_dists = 1 - combined_dists / max_valid\n",
    "\n",
    "        # constructing the lattice\n",
    "        agn_acc_lattice = tg.to_lattice(mapped_dists.reshape(new_avail_lattice.shape), new_avail_lattice)\n",
    "\n",
    "        agn_acc_list.append(agn_acc_lattice)\n",
    "\n",
    "    # combine agn_dist fields with base env info\n",
    "    env_info = env_info_base + agn_acc_list\n",
    "    \n",
    "    # Agent Loop\n",
    "    # for each agent ... \n",
    "    for a_id in range(agn_num):\n",
    "        # retrieve the list of the locations of the current agent\n",
    "        a_locs = agn_locs[a_id]\n",
    "        # retrieve the list of the prefernece to grow in the z plane of the current agent\n",
    "        a_expandz = agn_expandz[int(a_id)]\n",
    "        # retrieve the list of the maximum amount of voxels for each function\n",
    "        a_vox_req = agn_vox_req[a_id]\n",
    "        # retrieve the list of the amount of voxels of each function\n",
    "        a_vox_count = len(a_locs)\n",
    "       \n",
    "        # initialize the list of free neighbours\n",
    "        free_neighs = []\n",
    "        free_neighs_1d = []\n",
    "        free_neigh_weights = []    \n",
    "        \n",
    "        # Location loop\n",
    "        # for each location of the agent\n",
    "        for loc in a_locs:\n",
    "            \n",
    "            # here is decided if a function grows in the xy plane or in the xyz plane  \n",
    "            # retrieve the list of neighbours of the agent based on the stencil\n",
    "            z_neighs = new_avail_lattice.find_neighbours_masked(s_z, loc = loc)\n",
    "            \n",
    "            # retrieve the list of neighbours of the agent based on the stencil\n",
    "            xy_neighs = new_avail_lattice.find_neighbours_masked(s_xy, loc = loc)\n",
    "            \n",
    "            # neighs are stacked in sequence horizontally\n",
    "            neighs = np.hstack([z_neighs,xy_neighs])\n",
    "            # neigh_weights are stacked in sequence horizontally. z preference is variable, xy prefernce is 1.0.\n",
    "            # because it is 1.0 is will always grow horizontally and it will also grow vertically based on the weight of a_expandz\n",
    "            neigh_weights = np.hstack([np.full(z_neighs.shape, a_expandz), np.full(xy_neighs.shape,1.0)])\n",
    "            \n",
    "            # for each neighbour ...\n",
    "            # compare neighs and neigh_weights\n",
    "            for n, nw in zip(neighs, neigh_weights):\n",
    "                # compute 3D index of neighbour\n",
    "                neigh_3d_id = np.unravel_index(n, new_avail_lattice.shape)\n",
    "                # if the neighbour is available... \n",
    "                if new_avail_lattice[neigh_3d_id]:\n",
    "                    # add the neighbour to the list of free neighbours\n",
    "                    free_neighs.append(neigh_3d_id)\n",
    "                    free_neigh_weights.append(nw)\n",
    "                    free_neighs_1d.append(n)\n",
    "        \n",
    "\n",
    "        # check if found any free neighbour\n",
    "        if len(free_neighs)>0:   \n",
    "            # convert free neighbours to a numpy array\n",
    "            free_neighs = np.array(free_neighs)\n",
    "            free_neighs_1d = np.array(free_neighs_1d)   \n",
    "            \n",
    "            # uniq_neigh: neighbours that occur more than once are only called once\n",
    "            # unique_to_norm_order: numbers in free_neighs_1d replaced by positions of unig_neigh\n",
    "            # unique_neighs_count: counts the amount of times a neighbour appears in free_neighs_1d\n",
    "            uniq_neighs, unique_to_norm_order, unique_neighs_count = np.unique(free_neighs_1d, return_counts=True, return_inverse=True)   \n",
    "            \n",
    "            # voxel value is raised when a voxel appears more often in free_neighs_1d\n",
    "            # 1.5 is the indicator for preference to grow more in a square shape choosing a reoccuring neighbour.\n",
    "            # this could be a variable number for each space\n",
    "            extra_weight = (unique_neighs_count - 1) * 1.5 + 1\n",
    "           \n",
    "            # retrieving the entrance access value of the free neighbours\n",
    "            neigh_vals = []\n",
    "            # retrieve agent preferences\n",
    "            a_pref_dict = agn_info_df.loc[a_id]\n",
    "            # Neighbour Evaluation Loop\n",
    "            for neigh, neigh_w in zip(free_neighs,free_neigh_weights):\n",
    "                neigh_value = neigh_w\n",
    "                # for every lattice in the environment informations\n",
    "                # for i, info_lattice in enumerate(env_info):\n",
    "                for info_key, info_lattice in env_info_dict.items():\n",
    "                    # Here we utilise Fuzzy Logics to be able to compare different layers \n",
    "                    # of environmental information and evaluate the voxel for the agent. \n",
    "                    vox_val = info_lattice[tuple(neigh)]\n",
    "                    agn_vox_val = np.power(vox_val, a_pref_dict[info_key])\n",
    "                    neigh_value *= agn_vox_val\n",
    "                # add the neighbour value to the list of values\n",
    "                neigh_vals.append(neigh_value)\n",
    "                \n",
    "            # convert to numpy array\n",
    "            neigh_vals = np.array(neigh_vals)\n",
    "            # extra weight is added to voxel values\n",
    "            neigh_vals *= extra_weight[unique_to_norm_order] \n",
    "            \n",
    "            # select the neighbour with highest value \n",
    "            selected_int = np.argmax(neigh_vals) \n",
    "            selected_neigh_val = neigh_vals[selected_int]\n",
    "            # find 3D intiger index of selected neighbour\n",
    "            selected_neigh_3d_id = tuple(free_neighs[selected_int].T)\n",
    "            # find the location of the newly selected neighbour\n",
    "            selected_neigh_loc = np.array(selected_neigh_3d_id).flatten()\n",
    "            \n",
    "            # here we check if a function can still grow based on its current amount of voxels and the maximum required\n",
    "        if a_vox_count < a_vox_req:\n",
    "            # add the newly selected neighbour location to agent locations\n",
    "            agn_locs[a_id].append(selected_neigh_loc)\n",
    "            # set the newly selected neighbour as UNavailable (0) in the availability lattice\n",
    "            new_avail_lattice[selected_neigh_3d_id] = 0\n",
    "            # set the newly selected neighbour as OCCUPIED by current agent \n",
    "            # (-1 means not-occupied so a_id)\n",
    "            occ_lattice[selected_neigh_3d_id] = a_id\n",
    "            \n",
    "            # if the required amount of voxels has been reached, no more new neighbours will be added to the location list of that agent\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # constructing the new lattice\n",
    "    new_occ_lattice = tg.to_lattice(np.copy(occ_lattice), occ_lattice)\n",
    "    # adding the new lattice to the list of frames\n",
    "    frames.append(new_occ_lattice)\n",
    "    # adding one to the time counter\n",
    "    t += 1\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Visualizing the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p = pv.Plotter(notebook=True)\n",
    "\n",
    "base_lattice = frames[0]\n",
    "\n",
    "# Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data\n",
    "grid = pv.UniformGrid()\n",
    "grid.dimensions = np.array(base_lattice.shape) + 1\n",
    "# The bottom left corner of the data set\n",
    "grid.origin = base_lattice.minbound - base_lattice.unit * 0.5\n",
    "# These are the cell sizes along each axis\n",
    "grid.spacing = base_lattice.unit \n",
    "\n",
    "# adding the avilability lattice\n",
    "# new_init_avail_lattice.fast_vis(p)\n",
    "# new_avail_lattice.fast_vis(p)\n",
    "\n",
    "p.add_mesh(tri_to_pv(context_mesh), style='surface')\n",
    "\n",
    "# Make a dictionary for the annotations\n",
    "annotations = {\n",
    "    0: \"ent1\",\n",
    "    1: \"ent2\",\n",
    "    2: \"ent3.1\",\n",
    "    3: \"ent3.2\",\n",
    "    4: \"ent3.3\",\n",
    "    5: \"ent4\",\n",
    "    6: \"ent5\",\n",
    "    7: \"ent6\",\n",
    "    8: \"ent7\",\n",
    "    9: \"student\",\n",
    "    10: \"assisted\",\n",
    "    11: \"starter\",\n",
    "    12: \"restaurant\",\n",
    "    13: \"shop\",\n",
    "    14: \"cocooking\",\n",
    "    15: \"pub\",\n",
    "    16: \"gym\",\n",
    "    17: \"arcade\",\n",
    "    18: \"cinema\",\n",
    "    19: \"office\",\n",
    "    20: \"cowork\",\n",
    "    21: \"library\",\n",
    "    22: \"fablabs\",\n",
    "    23: \"catering\",\n",
    "    24: \"catering2\",\n",
    "    25: \"catering3\",\n",
    "    26: \"coffeehub\" \n",
    "    \n",
    "}\n",
    "# make a dictionary for customizations\n",
    "sargs = dict(\n",
    "    title_font_size=14,\n",
    "    label_font_size=6,\n",
    "    shadow=True,\n",
    "    n_labels=0,\n",
    "    italic=False,\n",
    "    fmt=\"%.0f\",\n",
    "    font_family=\"arial\",\n",
    "    height=0.8, \n",
    "    vertical=True, \n",
    "    position_x=1.0, \n",
    "    position_y=0.1\n",
    ")\n",
    "\n",
    "def create_mesh(value):\n",
    "    f = int(value)\n",
    "    lattice = frames[f]\n",
    "\n",
    "    # Add the data values to the cell data\n",
    "    grid.cell_arrays[\"Agents\"] = lattice.flatten(order=\"F\").astype(int)  # Flatten the array!\n",
    "    # filtering the voxels\n",
    "    threshed = grid.threshold([-0.1, agn_num - 0.9])\n",
    "    # adding the voxels\n",
    "    p.add_mesh(threshed, name='sphere', show_edges=True, opacity=1.0, show_scalar_bar=True, annotations=annotations, scalar_bar_args=sargs, cmap=\"tab20\")\n",
    "\n",
    "    return\n",
    "\n",
    "p.add_slider_widget(create_mesh, [0, n_frames], title='Time', value=0, event_type=\"always\", style=\"classic\", pointa=(0.1, 0.1), pointb=(0.9, 0.1))\n",
    "p.show(use_ipyvtk=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Saving lattice frames in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, lattice in enumerate(frames):                                                           \n",
    "    csv_path = os.path.relpath('../data/abm_mcda/abm_f_'+ f'{i:03}' + '.csv')                             \n",
    "    lattice.to_csv(csv_path)                                                                                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Shervin Azadi and Pirouz Nourian\n",
    "__changes_made_by__ \"Xam Adan\"\n",
    "__license__ = \"MIT\"\n",
    "__version__ = \"1.0\"\n",
    "__url__ = \"https://github.com/frankvahstal/spatial_computing_workshops\"\n",
    "__summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}